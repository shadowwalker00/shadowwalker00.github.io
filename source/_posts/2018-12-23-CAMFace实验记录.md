---
title: 'CAMFace实验记录'
date: 2018-12-23
tags: [Deep Learning]
---

# Pretrained Network vs Whole Network
<!--more-->
这部分对比几个方面的实验:

+ 使用Pretrained Weight并训练整个网络
+ 使用Pretraiend网络并训练新加层的参数 包括conv6  bias6 GAP bias
+ 所有参数均初始化

结果：在使用Pretrained Weight的基础上，进行whole network的retrain时performance最好。

# Assign Weight对Out层的节点

由于某些attribute可能没那么重要（原因在于人与人之间的diff也很大），所以就让那些重要的attribute的loss权重大点，不重要的权重小点。利用ICC value对output的中的每一个attribute进行赋值。

结果：这样的操作会导致performance的提升。

# fine-tune参数

需要fine-tune的参数有：

+ batchsize
+ weight_dacay_rate
+ momentum

| experiment | Batchsize | Weight_dacay_rate | momentum | Result          |
| ---------- | --------- | ----------------- | -------- | --------------- |
| #1         | 20        | 0.0005            | 0.9      | happy 0.7802    |
| #2         | 40        | 0.0005            | 0.9      | **cold 0.7813** |
| #3         | 60        | 0.0005            | 0.9      | cold 0.7724     |
| #4         | 80        | 0.0005            | 0.9      | cold 0.7679     |
| #5         | 40        | 0.005             | 0.9      | **cold 0.7861** |
| #6         | 40        | 0.05              | 0.9      | cold 0.7833     |
| #7         | 40        | 0.005             | 0.8      | cold 0.7763     |
| #8         | 40        | 0.005             | 0.95     | cold 0.7843     |
| #9         | 40        | 0.005             | 0.93     | cold 0.7853     |
| #10        | 40        | 0.005             | 0.88     | cold 0.7847     |

结果：最终参数选择batchsize 40，weight_decay_rate 0.005，momentum 0.9。模型文件叫做decay005-14。

# Network Change

原来的网络结构是：

['conv1_1/W:0', 'conv1_1/b:0', 'conv1_2/W:0', 'conv1_2/b:0', 'conv2_1/W:0', 'conv2_1/b:0', 'conv2_2/W:0', 'conv2_2/b:0', 'conv3_1/W:0', 'conv3_1/b:0', 'conv3_2/W:0', 'conv3_2/b:0', 'conv3_3/W:0', 'conv3_3/b:0', 'conv4_1/W:0', 'conv4_1/b:0', 'conv4_2/W:0', 'conv4_2/b:0', 'conv4_3/W:0', 'conv4_3/b:0', 'conv5_1/W:0', 'conv5_1/b:0', 'conv5_2/W:0', 'conv5_2/b:0', 'conv5_3/W:0', 'conv5_3/b:0', 'conv6/W:0', 'conv6/b:0', 'GAP/W:0', 'GAP/b:0']

注意在Conv5-3之后作者增加了一个conv6。这个实验中删除conv6，直接进行Global Average Pooling，再映射到Output上。

结果：cold 0.78699。结果显示与前面一节中的最好结果差不多，略低些。模型文件叫做noconv6-14。

# Filter部分attribute



# PCA实验

Global average pooling之后加一个PCA对1024 dimension进行降维。先利用之前的模型文件forward得到GAP之后的feature，训练一个PCA。

```python
pcaObj=PCA(n_components='mle',svd_solver='full',copy=True)
newData = pcaObj.fit_transform(pcaData)   
```

结果：最终降维后的dimension是。    。缺点是训练PCA速度慢。

分析：PCA是对输入特征的线性组合，增加一个hidden layer应该就可以。

# 增加Hidden Layer

在GAP输出的1024维输出后增加一个hidden layer。

Fine tune hidden layer的节点个数。

